# Semantic Kernel 处理不支持 Function Call 的大模型

## 1. 问题分析

当大模型不支持 Function Call 时，Semantic Kernel 有多种处理策略：

### 1.1 自动降级机制
```python
# Semantic Kernel 会自动检测模型能力
class ChatCompletionAgent:
    async def _get_chat_completion_service_and_settings(self, kernel, arguments):
        service, settings = kernel.select_ai_service(arguments=arguments, type=ChatCompletionClientBase)
        
        # 检查模型是否支持 Function Call
        if not service.supports_function_calling:
            # 自动禁用 Function Call
            settings.function_choice_behavior = FunctionChoiceBehavior.None_()
            print("⚠️  模型不支持 Function Call，已自动禁用")
        
        return service, settings
```

### 1.2 手动配置策略
```python
# 手动禁用 Function Call
agent = ChatCompletionAgent(
    service=create_ai_service(),
    function_choice_behavior=FunctionChoiceBehavior.None_(),  # 显式禁用
    plugins=[RepoFilePlugin()]  # 插件仍然可以加载
)
```

## 2. 替代方案

### 2.1 基于 Prompt 的函数调用

当模型不支持原生 Function Call 时，Semantic Kernel 可以通过 Prompt Engineering 来模拟：

```python
class PromptBasedFunctionCaller:
    def __init__(self, plugins: List[KernelPlugin]):
        self.plugins = plugins
        self.function_descriptions = self._generate_function_descriptions()
    
    def _generate_function_descriptions(self) -> str:
        """生成函数描述的文本"""
        descriptions = []
        for plugin in self.plugins:
            for func_name, func in plugin.functions.items():
                desc = f"""
Function: {func_name}
Description: {func.description}
Parameters: {func.parameters}
Example: {func.example if hasattr(func, 'example') else 'N/A'}
"""
                descriptions.append(desc)
        return "\n".join(descriptions)
    
    def create_enhanced_prompt(self, user_message: str) -> str:
        """创建增强的提示词"""
        return f"""
You are an AI assistant with access to the following functions:

{self.function_descriptions}

To use a function, respond with the following format:
FUNCTION_CALL: function_name
PARAMETERS: {{parameter_name: value, ...}}

User message: {user_message}

If you need to call a function, use the format above. Otherwise, respond normally.
"""
```

### 2.2 实际示例：CodeExecutionPlugin 的 Prompt 模式

```python
class CodeExecutionPlugin:
    """支持 Prompt 模式的代码执行插件"""
    
    @kernel_function(description="Run a Python code snippet. You can assume all the necessary packages are installed.")
    def run(self, code: str) -> str:
        """运行 Python 代码片段"""
        sandbox = AICodeSandbox(
            custom_image="python:3.12-slim",
            packages=["semantic_kernel"],
        )
        try:
            return sandbox.run_code(code)
        finally:
            sandbox.close()
    
    @staticmethod
    def get_prompt_description() -> str:
        """返回 Prompt 模式下的函数描述"""
        return """
Available Function: run_python_code
Description: Execute Python code and return the output
Usage: To run Python code, format your response as:
FUNCTION_CALL: run_python_code
PARAMETERS: {"code": "print('Hello, World!')"}

The code will be executed in a secure sandbox environment.
"""
```

### 2.3 Agent 的 Prompt 模式实现

```python
class PromptBasedAgent(CustomAgentBase):
    def __init__(self, plugins: List[object] = None):
        super().__init__(
            service=self._create_ai_service(Services.AZURE_OPENAI),
            plugins=plugins or [],
            function_choice_behavior=FunctionChoiceBehavior.None_(),  # 禁用原生 Function Call
        )
        self.prompt_function_caller = PromptBasedFunctionCaller(self.kernel.plugins)
    
    async def invoke(self, messages, **kwargs):
        # 增强用户消息，添加函数描述
        if isinstance(messages, str):
            enhanced_message = self.prompt_function_caller.create_enhanced_prompt(messages)
            messages = [ChatMessageContent(role=AuthorRole.USER, content=enhanced_message)]
        
        # 调用父类方法
        async for response in super().invoke(messages=messages, **kwargs):
            # 检查响应是否包含函数调用
            processed_response = await self._process_prompt_based_function_call(response)
            yield processed_response
    
    async def _process_prompt_based_function_call(self, response):
        """处理基于 Prompt 的函数调用"""
        content = response.message.content
        
        # 检查是否包含函数调用格式
        if "FUNCTION_CALL:" in content:
            try:
                # 解析函数调用
                func_name, parameters = self._parse_function_call(content)
                
                # 执行函数
                result = await self._execute_function(func_name, parameters)
                
                # 创建新的响应
                new_content = f"Function executed successfully. Result: {result}"
                response.message.content = new_content
                
            except Exception as e:
                response.message.content = f"Function execution failed: {str(e)}"
        
        return response
    
    def _parse_function_call(self, content: str) -> tuple[str, dict]:
        """解析函数调用格式"""
        import re
        import json
        
        # 提取函数名
        func_match = re.search(r'FUNCTION_CALL:\s*(\w+)', content)
        if not func_match:
            raise ValueError("Invalid function call format")
        
        func_name = func_match.group(1)
        
        # 提取参数
        params_match = re.search(r'PARAMETERS:\s*(\{.*?\})', content, re.DOTALL)
        if params_match:
            params_str = params_match.group(1)
            parameters = json.loads(params_str)
        else:
            parameters = {}
        
        return func_name, parameters
    
    async def _execute_function(self, func_name: str, parameters: dict):
        """执行函数"""
        # 查找函数
        for plugin in self.kernel.plugins.values():
            if hasattr(plugin, func_name):
                func = getattr(plugin, func_name)
                if callable(func):
                    return await func(**parameters)
        
        raise ValueError(f"Function {func_name} not found")
```

## 3. 混合模式支持

### 3.1 自适应函数调用策略

```python
class AdaptiveFunctionCallStrategy:
    def __init__(self, agent: ChatCompletionAgent):
        self.agent = agent
        self.supports_native_function_call = self._check_function_call_support()
    
    def _check_function_call_support(self) -> bool:
        """检查模型是否支持原生 Function Call"""
        try:
            # 尝试获取服务信息
            service = self.agent.service
            if hasattr(service, 'supports_function_calling'):
                return service.supports_function_calling
            
            # 基于模型名称判断
            model_name = getattr(service, 'model_id', '').lower()
            
            # 已知支持 Function Call 的模型
            supported_models = [
                'gpt-3.5-turbo', 'gpt-4', 'gpt-4-turbo', 'gpt-4o',
                'claude-3', 'gemini-pro'
            ]
            
            return any(model in model_name for model in supported_models)
            
        except Exception:
            return False
    
    async def invoke_with_adaptive_strategy(self, messages, **kwargs):
        """使用自适应策略调用"""
        if self.supports_native_function_call:
            print("✅ 使用原生 Function Call")
            # 使用原生 Function Call
            self.agent.function_choice_behavior = FunctionChoiceBehavior.Auto()
            async for response in self.agent.invoke(messages=messages, **kwargs):
                yield response
        else:
            print("🔄 使用 Prompt 模拟 Function Call")
            # 使用 Prompt 模拟
            prompt_agent = PromptBasedAgent(plugins=list(self.agent.kernel.plugins.values()))
            async for response in prompt_agent.invoke(messages=messages, **kwargs):
                yield response
```

### 3.2 配置驱动的策略选择

```python
class ConfigurableFunctionCallAgent(CustomAgentBase):
    def __init__(self, function_call_mode: str = "auto"):
        """
        Args:
            function_call_mode: "native", "prompt", "auto"
        """
        super().__init__(
            service=self._create_ai_service(Services.AZURE_OPENAI),
            plugins=[CodeExecutionPlugin(), RepoFilePlugin()],
        )
        self.function_call_mode = function_call_mode
        self._configure_function_call_behavior()
    
    def _configure_function_call_behavior(self):
        """配置函数调用行为"""
        if self.function_call_mode == "native":
            self.function_choice_behavior = FunctionChoiceBehavior.Auto()
        elif self.function_call_mode == "prompt":
            self.function_choice_behavior = FunctionChoiceBehavior.None_()
        elif self.function_call_mode == "auto":
            # 自动检测并配置
            if self._check_native_support():
                self.function_choice_behavior = FunctionChoiceBehavior.Auto()
            else:
                self.function_choice_behavior = FunctionChoiceBehavior.None_()
```

## 4. 实际测试示例

```python
# 测试不支持 Function Call 的场景
async def test_non_function_call_model():
    """测试不支持 Function Call 的模型"""
    
    # 创建模拟不支持 Function Call 的服务
    class NonFunctionCallService(ChatCompletionClientBase):
        supports_function_calling = False
        
        async def get_chat_message_contents(self, chat_history, settings, **kwargs):
            # 模拟简单的文本生成
            return [ChatMessageContent(
                role=AuthorRole.ASSISTANT,
                content="I'm a simple model without function calling support."
            )]
    
    # 创建 Agent
    agent = ChatCompletionAgent(
        service=NonFunctionCallService(),
        plugins=[CodeExecutionPlugin()],
        function_choice_behavior=FunctionChoiceBehavior.None_()  # 明确禁用
    )
    
    # 测试调用
    messages = "Please run this Python code: print('Hello, World!')"
    
    async for response in agent.invoke(messages=messages):
        print(f"Response: {response.message.content}")
        # 输出：I'm a simple model without function calling support.
```

## 5. 最佳实践建议

### 5.1 优雅降级策略

```python
class GracefulDegradationAgent(CustomAgentBase):
    async def invoke(self, messages, **kwargs):
        try:
            # 首先尝试原生 Function Call
            self.function_choice_behavior = FunctionChoiceBehavior.Auto()
            async for response in super().invoke(messages=messages, **kwargs):
                yield response
                
        except FunctionCallNotSupportedException:
            # 如果不支持，自动切换到 Prompt 模式
            print("⚠️  原生 Function Call 不支持，切换到 Prompt 模式")
            self.function_choice_behavior = FunctionChoiceBehavior.None_()
            
            # 重新处理消息
            enhanced_messages = self._enhance_messages_with_function_descriptions(messages)
            async for response in super().invoke(messages=enhanced_messages, **kwargs):
                processed_response = await self._process_prompt_function_calls(response)
                yield processed_response
```

### 5.2 兼容性检查工具

```python
class ModelCompatibilityChecker:
    """模型兼容性检查工具"""
    
    @staticmethod
    def check_function_call_support(service: ChatCompletionClientBase) -> dict:
        """检查模型的 Function Call 支持情况"""
        result = {
            "native_function_call": False,
            "prompt_based_simulation": True,
            "recommended_strategy": "prompt",
            "limitations": []
        }
        
        # 检查原生支持
        if hasattr(service, 'supports_function_calling'):
            result["native_function_call"] = service.supports_function_calling
        
        # 基于模型类型判断
        model_name = getattr(service, 'model_id', '').lower()
        
        if 'gpt-3.5-turbo' in model_name or 'gpt-4' in model_name:
            result["native_function_call"] = True
            result["recommended_strategy"] = "native"
        elif 'claude' in model_name:
            result["native_function_call"] = True
            result["recommended_strategy"] = "native"
        elif 'gemini' in model_name:
            result["native_function_call"] = True
            result["recommended_strategy"] = "native"
        else:
            result["limitations"].append("Model may not support native function calling")
            result["recommended_strategy"] = "prompt"
        
        return result
    
    @staticmethod
    def suggest_configuration(service: ChatCompletionClientBase) -> dict:
        """建议配置"""
        compatibility = ModelCompatibilityChecker.check_function_call_support(service)
        
        if compatibility["native_function_call"]:
            return {
                "function_choice_behavior": "FunctionChoiceBehavior.Auto()",
                "strategy": "native",
                "notes": "使用原生 Function Call 以获得最佳性能"
            }
        else:
            return {
                "function_choice_behavior": "FunctionChoiceBehavior.None_()",
                "strategy": "prompt_based",
                "notes": "使用 Prompt 模拟 Function Call，需要额外的响应解析逻辑"
            }
```

## 6. 总结

当大模型不支持 Function Call 时，Semantic Kernel 提供了多种解决方案：

### ✅ 支持的处理方式：
1. **自动降级**：框架自动检测并禁用 Function Call
2. **手动配置**：显式设置 `FunctionChoiceBehavior.None_()`
3. **Prompt 模拟**：通过 Prompt Engineering 模拟函数调用
4. **混合模式**：根据模型能力自动选择策略

### 🔧 实现策略：
- **插件仍然可用**：Plugin 系统依然工作，只是调用方式不同
- **优雅降级**：从原生 Function Call 平滑过渡到 Prompt 模式
- **兼容性检查**：提供工具检查模型能力并建议配置

### 📈 性能对比：
- **原生 Function Call**：最高效，结构化，精确
- **Prompt 模拟**：灵活，兼容性好，但需要额外解析逻辑
- **混合模式**：自适应，向后兼容，开发复杂度适中

这种设计保证了 Semantic Kernel 在各种 AI 模型上都能正常工作，体现了框架的健壮性和适应性。
